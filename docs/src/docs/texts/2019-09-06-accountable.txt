<p style="text-indent:0em">According to Fionntán O’Donnell, Senior Software Engineer at the BBC, <span class="text-note" data-note="68">“algorithms are not responsible, people are”</span>. The requirement to assign responsibility to a human being behind all automated cognitive processes is mainly a liability and insurance requirement. Late in the Industrial Revolution glass manufacturer Duralex simply assigned a number to each of its machines which would be imprinted at the bottom of the glass in order to track the faulty ones. In the machine learning and AI realm though, the accountability problem lies in tracking the location and logic behind <span class="text-note" data-note="69">algorithmic decisions</span>. It can be nearly impossible to assign responsibility to one entity within systems which may be dispersed and interlaced in space and time.</p>
<p style="text-indent:2em">Engineers are currently developing AI algorithms which could explain to humans reasons for (or steps of) their <span class="text-note" data-note="70">behaviours</span>. However it still seems unlikely in current paradigms that we could ever locate a fault within algorithms precisely enough to distribute liability to computers or the algorithms themselves. Mea culpa only works with the underwriting of a tacit agreement between entities that have common fears of punishment - which most humans do. ‘jail’, ‘fines’, ‘life’ and ‘death’ can be understood and avoided systematically by AIs while still remaining abstract concepts that are ‘sensed’ rather than ‘felt’. In animal terms they could be (and have often been) portrayed as sociopaths, but these animal terms cease to be useful and mostly explain the suspicion and violence that is unleashed from the <span class="text-note" data-note="71">‘uncanny valley’</span>.</p>
<p style="text-indent:2em">Human journalists and editors are of course the primary gatekeepers of photographic and textural data. In computer science terminology, they turn data into information that carries meaning. They filter and digest content to feed an audience equipped with similar senses but without the trained eye for composition and foregrounding. Albert van Helden and Thomas Hankins write that <span class="text-note" data-note="72">“instruments determine what can be done, so they also determine to some extent what can be thought”</span>. Journalists might now be thought of as instruments that augment and limit the ways in which facts are related to each other. The humans amongst them are highly restrained by collective memory, apophenia and the perception of time always moving forwards - but maybe not for much longer.</p>
<p style="text-indent:2em">AI systems sense the world differently to us, often beyond our patterns of recognition and with different priorities. Through their ability to analyse exhaustive banks of media content, AI systems have the potential to find correlations between facts which aren’t visible to a human eye or are beyond the scale of human cognition. They can allow us to zoom in and out to witness contexts and datasets much smaller, wider or longer than our lifetime’s, body’s and nation’s reading, helping us becoming ‘big data journalists’ with augmented perspective. No doubt with some <span class="text-note" data-note="73">lossiness</span> in translation to keep us guessing.</p>
<p style="text-indent:2em">Recent political referendums in Europe and the US have shown ways in which mainstream media have been unable to bypass popular attraction towards nationalism and fear, making themselves complicit in circular and self-propagating subjects of <span class="text-note" data-note="74">‘public interest’</span>. They demonstrate that news organisations are not leading the public interest and that what were once passive viewers now seek a more active role in defining the meaning of events in space. There is undeniably a search for technologies that will bypass the black hole of identity politics that forms the current nexus of individual and collective at the scale of mass-media.</p>
<p style="text-indent:2em">Philosopher Paul Virilio writes that <span class="text-note" data-note="75">“the revolution of real information is also a revolution in virtual disinformation”</span>. With access to information superhighways, it has become easier to scrape for news items in order to support any kind of argument. We can find enough ‘stock content’ online to challenge any opinion or approve any kind of statement. It has now become easier to falsify correlations between facts and draw shortcuts to explain the mechanisms behind impenetrably complex forces and systems.</p>
<p style="text-indent:2em">Techniques of ‘fact hijacking’ are used to suit simplistic statements and beliefs. Their extremes often result in the absurdist build up of conspiracy theories, from chemtrails to <span class="text-note" data-note="76">Barack Obama’s birth certificate</span>. These theories become as legendary as they are pathetic, relying on inexhaustible supplies of eccentric associations to contradict refutation attempts. This seems particularly worrying in the scenario of ‘citizen journalism’. To prevent AI systems from becoming as recklessly creative as conspiracy theorists, our attention should be drawn towards the transparency and explicitness of their decision processes - maybe by having humans checking fact checkers and by building AI conspiracy theorists as controls.</p>
<p style="text-indent:2em">To pursue our speculations, we could project ourselves even further and see the potential of AI not just in re-organising and delivering facts but also in guiding journalists in collecting them - a sort of Pokémon Go for real world events. We could imagine a network of journalists orchestrated by a Bot working collaboratively in order to cover complementary subjects, events and places; a bit like the Uber app showing drivers areas where the fare rate is higher, and semi-directing orchestrating their movements.</p>
<p style="text-indent:2em">The platform <span class="text-note" data-note="77">Bootlegger</span> aims to do just that in the broadcasting environment by offering several templates that guide users to record live events. We could envision that similar platforms to Bootlegger could start anticipating news topics and locations thanks to AI algorithms. It could also act as a fact forecaster based on all the information uploaded by its users. A tool like <span class="text-note" data-note="78">PredPol</span> already demonstrates that predicting threats and ‘predictive policing’ can now be achieved, so why not news items? The danger with such technology is its embodiment of sexual and <span class="text-note" data-note="79">racial biases</span> <span class="text-note" data-note="80">(or not)</span>. In the scenario of ‘predictive news gathering’ a biased AI would possibly be directing citizen journalists continuously towards specific suburbs, which could have unexpected consequences on demographic movements, quality of space and the places where incidents occur in the first place.</p> 
<p style="text-indent:2em">The point here is that datasets are bound to capture a biased past or collection method and so we must be literate in their narrative qualities in order to not entrench the suppressive patterns of history into our future. Of great concern is preventing AI from covering news ‘unequally’ and repeating what we already have, which may be achieved if it goes on searching for effectual linkages rather than indexing sensation and popularity.</p>
<br>
Up next: <i>News for cyborgs</i>
