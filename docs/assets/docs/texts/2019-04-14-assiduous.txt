<p style="text-indent:0em">Over the last couple of weeks Thomas has spent several days in Salford and London meeting with employees of <span class="text-note" data-note="1">BBC Research and Development</span> and <span class="text-note" data-note="2">BBC News Lab</span>, in order to get an idea of what working for a news organisation might be like in the future. From his interviews, field notes and reflections, we wrote eight thematic posts that expound the current implementation of automation and AI in the field of news media, and project where it could all lead next. The questions raised are technical, ethical, ideological, philosophical and everything in between. Altogether they seem to call for a pluralist reformation of what the phrase ‘you know’ means in the activities of media space.</p>
<p style="text-indent:2em">The logical starting point for conversations of automation is the BBC’s development of softwares that are already used to facilitate employees workflows. These ‘tools’, as BBC employees call them, assist in sifting through exhaustive archives, annotating and editing footages, broadcasting videos and tailoring online content around individual user profiles. The tools are developed in parallel to each other and so are intended to be complementary.</p>
<p style="text-indent:2em">The BBC is also using machine learning (ML) algorithms to automate some of the processes of these tools, so that much of the cognitive labour of sorting and editing is reduced or even erased. The BBC’s usage of ML is in line with what most competitive content providers are implementing but the BBC is better placed than most to embark on this. Machine learning requires huge datasets to be useful and the BBC already has an exhaustive archive of video, sound and text content gathered over almost a century since its inception. By contrast, Alphabet first had to purchase YouTube to acquire video datasets for <span class="text-note" data-note="3">machine learning</span>.</p> 
<p style="text-indent:2em">Machine learning allows the BBC to find patterns in their own methods for producing media, and to then replicate and streamline specific tasks. One of the BBC’s current <span class="text-note" data-note="4">R&D experiments</span> consists of using sets of ‘comedy quiz’ footage to train computers to ‘understand’ (i.e. correlate) the relationship between the framing of a shot and the message or style being delivered in it. By using their custom-made browser tool to <span class="text-note" data-note="5">edit footage</span> and another custom-made tool that broadcasts through an <span class="text-note" data-note="6">IP network</span>, they can effectively automate the shooting of future shows in a ‘comedy quiz style’, as determined by the trained ML algorithm. If they use UHD cameras (which are now considered low cost equipment) to frame a scene and then crop it into HD, they will emerge with already-cut footage that resembles the ‘real deal’ in style if not substance. The BBC imagines that with such processes it can potentially make live event coverage “more accessible to smaller crews with limited budgets” and “simplify production for <span class="text-note" data-note="7">novice users</span>”, and we can easily see why.</p>                                               
<p style="text-indent:2em">Another experiment which also aims to expand production relies on content generated by the audience of a single event. The team has collaborated with several European universities and companies on the development of an app called <span class="text-note" data-note="8">COGNITUS</span> which compresses video content that an audience uploads via a smartphone. The app uses machine learning to enhance the audio and video quality of this User Generated Content (UGC) and bring it in line with BBC quality standards. In addition to a custom-build <span class="text-note" data-note="9">HDR system</span>, COGNITUS also uses ML to increase the number of pixels in each frame by either filling in missing pixels by looking at the surrounding ones or by directly interpreting low-res frames and their <span class="text-note" data-note="10">textures</span>. A similar process is also applied to sound by reducing noise in <span class="text-note" data-note="11">speeches</span>.</p>
<p style="text-indent:2em">Even from a superficial look in at these two experiments the beginnings of a massive shift of labour in media production are apparent, and not just in the editing room: We can anticipate the ease in which these tools could become accessible to a wider set of users. Could it be that the traditional tasks of journalists and editors become re-distributed to a larger, less skilled and more dispersed group? If much of the processing of media is automated, the distinction between reporter, producer and audience might become very hazy indeed.</p>
<p style="text-indent:2em">Secondly, when enough ‘tools’ of automation are in place that their overlaps start to become as seamless and intrinsic to their operation as the content itself, what will the known media landscape look like? Thomas didn’t manage to find someone at the BBC who would indulge in such grand projections from their research. This, one imagines, is in part because by nature the BBC is not in the business of speculation - although we may as well speculate on the future of that too. 
<p style="text-indent:2em">In the meantime, we decided to try and answer the question ourselves and see what might happen when we stitch together some existing BBC ‘tools’. The conclusion is by now unsurprising: From the filming and uploading of UGC through to its editing and delivery, it appears that nearly the entire production line of news could be automated.</p> 
<br>
Up next: <i>Citizen Journalism</i>
